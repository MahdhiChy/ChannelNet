{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from models import interpolation, SRCNN_train, SRCNN_model, SRCNN_predict, DNCNN_train, DNCNN_model, DNCNN_predict\n",
    "#from scipy.misc import imresize\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.isfile(\"C:/Users/golam/Documents/ChannelNet-master/Perfect_H_40000.mat\")  #这里最好设置一个指定的文件路径，不要设置相对文件路径\n",
    "os.path.isfile(\"C:/Users/golam/Documents/ChannelNet-master/My_noisy_H_22.mat\")   #这里最好设置一个指定的文件路径，不要设置相对文件路径\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data:Perfect_H_40000.mat\n",
    "# noisy: My_noisy_H_22.mat\n",
    "if __name__ == \"__main__\":\n",
    "    # load datasets \n",
    "    channel_model = \"VehA\"\n",
    "    SNR = 22\n",
    "    Number_of_pilots = 48\n",
    "    perfect = loadmat(\"C:/Users/golam/Documents/ChannelNet-master/Perfect_H_40000.mat\")['My_perfect_H']\n",
    "    noisy_input = loadmat(\"C:/Users/golam/Documents/ChannelNet-master/My_noisy_H_22.mat\")['My_noisy_H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 40000/40000 [02:50<00:00, 234.42it/s]\n"
     ]
    }
   ],
   "source": [
    "interp_noisy = interpolation(noisy_input , SNR , Number_of_pilots , 'rbf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     interp_noisy = np.load(\"interp_noisy.npy\")\n",
    "#     np.save('interp_noisy.npy',interp_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect_image = np.zeros((len(perfect),72,14,2))\n",
    "perfect_image[:,:,:,0] = np.real(perfect)\n",
    "perfect_image[:,:,:,1] = np.imag(perfect)\n",
    "perfect_image = np.concatenate((perfect_image[:,:,:,0], perfect_image[:,:,:,1]), axis=0).reshape(2*len(perfect), 72, 14, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### ------ training SRCNN ------ #######\n",
    "\n",
    "idx_random = np.random.rand(len(perfect_image)) < (1/9)  # uses 32000 from 36000 as training and the rest as validation\n",
    "train_data, train_label = interp_noisy[idx_random,:,:,:] , perfect_image[idx_random,:,:,:]\n",
    "val_data, val_label = interp_noisy[~idx_random,:,:,:] , perfect_image[~idx_random,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x157c4803340>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRCNN_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 72, 14, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 72, 14, 64)        5248      \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 72, 14, 32)        2080      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 72, 14, 1)         801       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8129 (31.75 KB)\n",
      "Trainable params: 8129 (31.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00964, saving model to SRCNN_check.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\golam\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 0.00964 to 0.00499, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.00499 to 0.00331, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.00331 to 0.00275, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.00275 to 0.00247, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.00247 to 0.00228, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00228\n",
      "\n",
      "Epoch 8: val_loss improved from 0.00228 to 0.00207, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.00207 to 0.00199, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.00199 to 0.00198, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.00198 to 0.00196, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.00196 to 0.00193, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00193\n",
      "\n",
      "Epoch 14: val_loss improved from 0.00193 to 0.00191, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.00191 to 0.00187, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.00187 to 0.00182, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.00182 to 0.00181, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 18: val_loss improved from 0.00181 to 0.00173, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00173\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00173\n",
      "\n",
      "Epoch 21: val_loss improved from 0.00173 to 0.00166, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00166\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00166\n",
      "\n",
      "Epoch 24: val_loss improved from 0.00166 to 0.00163, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00163\n",
      "\n",
      "Epoch 26: val_loss improved from 0.00163 to 0.00162, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00162\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00162\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00162\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00162\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00162\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00162\n",
      "\n",
      "Epoch 33: val_loss improved from 0.00162 to 0.00158, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 34: val_loss improved from 0.00158 to 0.00157, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00157\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00157\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00157\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00157\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00157\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00157\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00157\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00157\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00157\n",
      "\n",
      "Epoch 44: val_loss improved from 0.00157 to 0.00157, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 45: val_loss improved from 0.00157 to 0.00156, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00156\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00156\n",
      "\n",
      "Epoch 48: val_loss improved from 0.00156 to 0.00153, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00153\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00153\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00153\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00153\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00153\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00153\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00153\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00153\n",
      "\n",
      "Epoch 57: val_loss improved from 0.00153 to 0.00151, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00151\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00151\n",
      "\n",
      "Epoch 60: val_loss improved from 0.00151 to 0.00146, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00146\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00146\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00146\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00146\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00146\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00146\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00146\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00146\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00146\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00146\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00146\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00146\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00146\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00146\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00146\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00146\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00146\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00146\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00146\n",
      "\n",
      "Epoch 80: val_loss improved from 0.00146 to 0.00143, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 94: val_loss improved from 0.00143 to 0.00143, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 110: val_loss improved from 0.00143 to 0.00141, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00141\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00141\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00141\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00141\n",
      "\n",
      "Epoch 115: val_loss improved from 0.00141 to 0.00139, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00139\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00139\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00139\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00139\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00139\n",
      "\n",
      "Epoch 121: val_loss improved from 0.00139 to 0.00137, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 126: val_loss improved from 0.00137 to 0.00137, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 146: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 155: val_loss improved from 0.00137 to 0.00137, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 168: val_loss improved from 0.00137 to 0.00135, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.00135\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.00135\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.00135\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.00135\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.00135\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.00135\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.00135\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.00135\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.00135\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.00135\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.00135\n",
      "\n",
      "Epoch 180: val_loss improved from 0.00135 to 0.00134, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.00134\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.00134\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.00134\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.00134\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.00134\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.00134\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.00134\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.00134\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.00134\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.00134\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.00134\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.00134\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.00134\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.00134\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.00134\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.00134\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.00134\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.00134\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.00134\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.00134\n",
      "\n",
      "Epoch 201: val_loss improved from 0.00134 to 0.00132, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 202: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 203: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 204: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 206: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 207: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 208: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 209: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 211: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 212: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 213: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 214: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 215: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 216: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 217: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 218: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 219: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 221: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 222: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 223: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 224: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 225: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 226: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 227: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 228: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 229: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 230: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 231: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 232: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 233: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 234: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 236: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 237: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 238: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 239: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 241: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 242: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 243: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 244: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 245: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 246: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 247: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 248: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 249: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 251: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 252: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 253: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 254: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 255: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 256: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 257: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 258: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 259: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 260: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 261: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 262: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 263: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 264: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 265: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 266: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 267: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 268: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 269: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 270: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 271: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 272: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 273: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 274: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 275: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 276: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 277: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 278: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 279: val_loss improved from 0.00132 to 0.00131, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 280: val_loss did not improve from 0.00131\n",
      "\n",
      "Epoch 281: val_loss did not improve from 0.00131\n",
      "\n",
      "Epoch 282: val_loss did not improve from 0.00131\n",
      "\n",
      "Epoch 283: val_loss did not improve from 0.00131\n",
      "\n",
      "Epoch 284: val_loss did not improve from 0.00131\n",
      "\n",
      "Epoch 285: val_loss did not improve from 0.00131\n",
      "\n",
      "Epoch 286: val_loss did not improve from 0.00131\n",
      "\n",
      "Epoch 287: val_loss did not improve from 0.00131\n",
      "\n",
      "Epoch 288: val_loss did not improve from 0.00131\n",
      "\n",
      "Epoch 289: val_loss did not improve from 0.00131\n",
      "\n",
      "Epoch 290: val_loss did not improve from 0.00131\n",
      "\n",
      "Epoch 291: val_loss did not improve from 0.00131\n",
      "\n",
      "Epoch 292: val_loss did not improve from 0.00131\n",
      "\n",
      "Epoch 293: val_loss did not improve from 0.00131\n",
      "\n",
      "Epoch 294: val_loss improved from 0.00131 to 0.00131, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 295: val_loss did not improve from 0.00131\n",
      "\n",
      "Epoch 296: val_loss did not improve from 0.00131\n",
      "\n",
      "Epoch 297: val_loss did not improve from 0.00131\n",
      "\n",
      "Epoch 298: val_loss did not improve from 0.00131\n",
      "\n",
      "Epoch 299: val_loss did not improve from 0.00131\n",
      "\n",
      "Epoch 300: val_loss did not improve from 0.00131\n"
     ]
    }
   ],
   "source": [
    "SRCNN_train(train_data ,train_label, val_data , val_label , channel_model , Number_of_pilots , SNR )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training 300 epochs, the val_loss improved from inf to 0.00133, saving model to SRCNN_VehA_48_22.h5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277/277 [==============================] - 11s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "####### ------ prediction using SRCNN ------ #######\n",
    "srcnn_pred_train = SRCNN_predict(train_data, channel_model , Number_of_pilots , SNR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2224/2224 [==============================] - 63s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "srcnn_pred_validation = SRCNN_predict(val_data, channel_model , Number_of_pilots , SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8853, 72, 14, 1)\n"
     ]
    }
   ],
   "source": [
    "print(srcnn_pred_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result of prediction\n",
    "np.savetxt('srcnn_pred_train.txt',srcnn_pred_train[0][0])\n",
    "np.savetxt('srcnn_pred_validation.txt',srcnn_pred_validation[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x157ccc47130>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNCNN_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)       [(None, None, None, 1)]      0         []                            \n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)         (None, None, None, 64)       640       ['input_10[0][0]']            \n",
      "                                                                                                  \n",
      " activation_95 (Activation)  (None, None, None, 64)       0         ['conv2d_112[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)         (None, None, None, 64)       36928     ['activation_95[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_90 (Ba  (None, None, None, 64)       256       ['conv2d_113[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_96 (Activation)  (None, None, None, 64)       0         ['batch_normalization_90[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)         (None, None, None, 64)       36928     ['activation_96[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_91 (Ba  (None, None, None, 64)       256       ['conv2d_114[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_97 (Activation)  (None, None, None, 64)       0         ['batch_normalization_91[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)         (None, None, None, 64)       36928     ['activation_97[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_92 (Ba  (None, None, None, 64)       256       ['conv2d_115[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_98 (Activation)  (None, None, None, 64)       0         ['batch_normalization_92[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)         (None, None, None, 64)       36928     ['activation_98[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_93 (Ba  (None, None, None, 64)       256       ['conv2d_116[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_99 (Activation)  (None, None, None, 64)       0         ['batch_normalization_93[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)         (None, None, None, 64)       36928     ['activation_99[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_94 (Ba  (None, None, None, 64)       256       ['conv2d_117[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_100 (Activation  (None, None, None, 64)       0         ['batch_normalization_94[0][0]\n",
      " )                                                                  ']                            \n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)         (None, None, None, 64)       36928     ['activation_100[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_95 (Ba  (None, None, None, 64)       256       ['conv2d_118[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_101 (Activation  (None, None, None, 64)       0         ['batch_normalization_95[0][0]\n",
      " )                                                                  ']                            \n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)         (None, None, None, 64)       36928     ['activation_101[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_96 (Ba  (None, None, None, 64)       256       ['conv2d_119[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_102 (Activation  (None, None, None, 64)       0         ['batch_normalization_96[0][0]\n",
      " )                                                                  ']                            \n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)         (None, None, None, 64)       36928     ['activation_102[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_97 (Ba  (None, None, None, 64)       256       ['conv2d_120[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_103 (Activation  (None, None, None, 64)       0         ['batch_normalization_97[0][0]\n",
      " )                                                                  ']                            \n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)         (None, None, None, 64)       36928     ['activation_103[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_98 (Ba  (None, None, None, 64)       256       ['conv2d_121[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_104 (Activation  (None, None, None, 64)       0         ['batch_normalization_98[0][0]\n",
      " )                                                                  ']                            \n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)         (None, None, None, 64)       36928     ['activation_104[0][0]']      \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_99 (Ba  (None, None, None, 64)       256       ['conv2d_122[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_105 (Activation  (None, None, None, 64)       0         ['batch_normalization_99[0][0]\n",
      " )                                                                  ']                            \n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)         (None, None, None, 64)       36928     ['activation_105[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_100 (B  (None, None, None, 64)       256       ['conv2d_123[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_106 (Activation  (None, None, None, 64)       0         ['batch_normalization_100[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)         (None, None, None, 64)       36928     ['activation_106[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_101 (B  (None, None, None, 64)       256       ['conv2d_124[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_107 (Activation  (None, None, None, 64)       0         ['batch_normalization_101[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)         (None, None, None, 64)       36928     ['activation_107[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_102 (B  (None, None, None, 64)       256       ['conv2d_125[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_108 (Activation  (None, None, None, 64)       0         ['batch_normalization_102[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)         (None, None, None, 64)       36928     ['activation_108[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_103 (B  (None, None, None, 64)       256       ['conv2d_126[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_109 (Activation  (None, None, None, 64)       0         ['batch_normalization_103[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)         (None, None, None, 64)       36928     ['activation_109[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_104 (B  (None, None, None, 64)       256       ['conv2d_127[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_110 (Activation  (None, None, None, 64)       0         ['batch_normalization_104[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)         (None, None, None, 64)       36928     ['activation_110[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_105 (B  (None, None, None, 64)       256       ['conv2d_128[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_111 (Activation  (None, None, None, 64)       0         ['batch_normalization_105[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)         (None, None, None, 64)       36928     ['activation_111[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_106 (B  (None, None, None, 64)       256       ['conv2d_129[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_112 (Activation  (None, None, None, 64)       0         ['batch_normalization_106[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)         (None, None, None, 64)       36928     ['activation_112[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_107 (B  (None, None, None, 64)       256       ['conv2d_130[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_113 (Activation  (None, None, None, 64)       0         ['batch_normalization_107[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)         (None, None, None, 1)        577       ['activation_113[0][0]']      \n",
      "                                                                                                  \n",
      " subtract_5 (Subtract)       (None, None, None, 1)        0         ['input_10[0][0]',            \n",
      "                                                                     'conv2d_131[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 670529 (2.56 MB)\n",
      "Trainable params: 668225 (2.55 MB)\n",
      "Non-trainable params: 2304 (9.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m####### ------ training DNCNN ------ #######\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mDNCNN_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_label\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_model\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNumber_of_pilots\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSNR\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\ChannelNet-master\\ChannelNet-master\\models.py:159\u001b[0m, in \u001b[0;36mDNCNN_train\u001b[1;34m(train_data, train_label, val_data, val_label, channel_model, num_pilots, SNR)\u001b[0m\n\u001b[0;32m    155\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDNCNN_check.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    156\u001b[0m                              save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    157\u001b[0m callbacks_list \u001b[38;5;241m=\u001b[39m [checkpoint]\n\u001b[1;32m--> 159\u001b[0m \u001b[43mdncnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_label\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m dncnn_model\u001b[38;5;241m.\u001b[39msave_weights(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDNCNN_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m channel_model \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(num_pilots) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(SNR) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####### ------ training DNCNN ------ #######\n",
    "DNCNN_train(train_data ,train_label, val_data , val_label , channel_model , Number_of_pilots , SNR )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "After training 200 epochs, the val_loss improved from 0.0935 to 0.00106, saving model to DNCNN_VehA_48_22.h5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
